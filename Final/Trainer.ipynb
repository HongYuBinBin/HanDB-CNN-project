{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile, os\n",
    "import torch\n",
    "import torchvision            \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from HW_CNN_dataset import Dataset\n",
    "\n",
    "import sys\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#File_NAME = sys.argv[1]\n",
    "\n",
    "#print(File_NAME)\n",
    "\n",
    "#class_num = 0\n",
    "#train_X = []\n",
    "#train_y = []\n",
    "\n",
    "\n",
    "def Dataset(File_NAME, label, class_num):          # label?\n",
    "    #class_num = 0                                                                                                             \n",
    "    train_X = []                                                                                                              \n",
    "    train_y = [] \n",
    "    for folderName, subFolder, fileNames in os.walk('./PE92_train/'+str(File_NAME)):\n",
    "        for fileName in fileNames:\n",
    "            if fileName == '.DS_Store':\n",
    "                continue\n",
    "            fileName = './PE92_train/'+str(File_NAME)+'/'+fileName\n",
    "            fp = open(fileName, 'r+b')\n",
    "            print(fileName)\n",
    "            header = fp.read(8)\n",
    "            width = 1\n",
    "            class_num += 1\n",
    "            while(1):\n",
    "                code = int.from_bytes(fp.read(2), \"big\")\n",
    "                if not code:\n",
    "                    break\n",
    "                width = int.from_bytes(fp.read(1), \"big\") \n",
    "                height = int.from_bytes(fp.read(1), \"big\")    \n",
    "                type = fp.read(1)\n",
    "                reserved = fp.read(1)\n",
    "                data = np.zeros(shape=(height, width), dtype=np.int)\n",
    "                for i in range(height):\n",
    "                    for j in range(width):\n",
    "                        data[i][j] = int.from_bytes(fp.read(1), \"big\")\n",
    "                resized = resize(data, (32, 32))\n",
    "                resized = resized * pow(10, 18)\n",
    "                re = []\n",
    "                for i in range(len(resized[0])):\n",
    "                    for j in range(len(resized[1])):\n",
    "                        re.append(resized[i][j])\n",
    "                train_X.append(re)\n",
    "                train_y.append(code)\n",
    "\n",
    "\n",
    "    print(\"class_num =\", class_num)\n",
    "            \n",
    "    train_X_np = np.asarray(train_X, dtype='float32')\n",
    "    train_y_np = np.asarray(train_y, dtype='int')\n",
    "    #label = []          # label?\n",
    "\n",
    "    for id, x in enumerate(train_y_np):\n",
    "        if x in label:\n",
    "            continue\n",
    "        else:\n",
    "            label.append(x)\n",
    "    for id, x in enumerate(train_y_np):\n",
    "        train_y_np[id] = label.index(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_X_np, train_y_np, test_size=0.15)\n",
    "\n",
    "            \n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "    torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "    # create feature and targets tensor for test set.\n",
    "    torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "    torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "\n",
    "    #torch_X_train = torch_X_train.view(-1, 1,28,28).float()\n",
    "    torch_X_train = torch_X_train.view(-1, 1,32,32).float()\n",
    "    #torch_X_test = torch_X_test.view(-1,1,28,28).float()\n",
    "    torch_X_test = torch_X_test.view(-1,1,32,32).float()\n",
    "    print(torch_X_train.shape)\n",
    "    print(torch_X_test.shape)\n",
    "\n",
    "    # Pytorch train and test sets\n",
    "    train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "    test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "    return train, test, class_num, BATCH_SIZE, label          # label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "File_NAME_list = ['b1','b2','b3','b4','b5','b6','b7','b8','b9','ba','bb','bc','bd','be','bf','c1','c2','c3','c4','c5','c6','c7']\n",
    "\n",
    "print(File_NAME_list)\n",
    "\n",
    "for File_NAME in File_NAME_list:\n",
    "    train, test = Dataset(File_NAME)\n",
    "\n",
    "# data loader\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "#1d로 받고 transpose 시켜서 2d로 바꿔서 입력 방법 찾아내기\n",
    "'''\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "MODEL_NAME = 'CNN2'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"MODEL_NAME = {}, DEVICE = {}\".format(MODEL_NAME, DEVICE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n",
    "        #self.fc1 = nn.Linear(3*3*64, 256)\n",
    "        self.fc1 = nn.Linear(64*21*21, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1,21*21*64 )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "'''\n",
    "class_num = 94\n",
    "\n",
    "class CNN2(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        super(CNN2, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            #nn.BatchNorm2d(32), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            #nn.BatchNorm2d(32), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "            #nn.BatchNorm2d(32), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, stride=2, padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, class_num)\n",
    "        )\n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "        \n",
    "cnn = CNN2(class_num)\n",
    "if use_cuda:\n",
    "    cnn = cnn.cuda()\n",
    "print(cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#MODEL_NAME = 'DNN'\n",
    "#DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(\"MODEL_NAME = {}, DEVICE = {}\".format(MODEL_NAME, DEVICE))\n",
    "\n",
    "\n",
    "#normalizaion 해놓기\n",
    "#교수님 코드 비교해서 부족한 점 채워넣기\n",
    "\n",
    "\n",
    "# Model_load                                                                                         \n",
    "'''\n",
    "device = torch.device(\"cuda\")\n",
    "#model = TheModelClass(*args, **kwargs)                                                        \n",
    "#optimizer = TheOptimizerClass(*args, **kwargs)                                                      \n",
    "checkpoint = torch.load(\"./model_save/model_HW_CNN.pth\")\n",
    "cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#num_epochs = checkpoint['epoch']                                                                    \n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "model.train()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, class_num):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 30\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    class_num = class_num\n",
    "    #cnn = CNN2()\n",
    "    #cnn = model\n",
    "    '''\n",
    "    #model = TheModelClass(*args, **kwargs)                                                              \n",
    "    #optimizer = TheOptimizerClass(*args, **kwargs)                                                      \n",
    "    checkpoint = torch.load(\"./model_save/model_HW_CNN2_.pth\")\n",
    "    cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    #num_epochs = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    cnn.eval()\n",
    "    '''\n",
    "    cnn.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            #if use_cuda:          # GPU 사용가능 환경이라면 Tensor를 GPU에서 사용하는 형태로 변환\n",
    "            #    var_X_batch, var_y_batch = var_X_batch.cuda(), var_y_batch.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            #print(correct)\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
    "\n",
    "    torch.save({\n",
    "    #'epoch': EPOCHS,\n",
    "    'model_state_dict': cnn.state_dict(),\n",
    "           'optimizer_state_dict': optimizer.state_dict(),\n",
    "           'loss': loss\n",
    "           }, \"./model_save/model_HW_CNN2_2_.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    acc = 0\n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        #print(test_imgs.shape)                                                                                                                                     \n",
    "        test_imgs, test_labels = test_imgs.to(DEVICE), test_labels.to(DEVICE)\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        #if use_cuda:                                                                                                                                               \n",
    "        #    test_imgs, test_labels = test_imgs.cuda(), test_labels.cuda()                                                                                          \n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        acc += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}\".format( float(acc) / (len(test_loader)*BATCH_SIZE)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "File_NAME_list = ['b0','b2','c0', 'c1','b3','b4','b5','b6','b7','b8','b9','ba','bb','bc','bd','be','bf','b1','c2','c3','c4','c5','c6','c7','c8']\n",
    "#File_NAME_list = ['b2','c1','b3', 'b4', 'b5','b6', 'b7', 'b8', 'b9', 'ba', 'bb', 'bc', 'bd']\n",
    "\n",
    "#File_NAME_list = ['b0', 'b2', 'c0']\n",
    "label = []\n",
    "class_num = 0\n",
    "\n",
    "print(File_NAME_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for File_NAME in File_NAME_list:\n",
    "    train, test, class_num, BATCH_SIZE, label = Dataset(File_NAME,label, class_num)          # label??\n",
    "\n",
    "    if File_NAME == 'b0':\n",
    "        train_ = train\n",
    "        test_ = test\n",
    "\n",
    "    else:\n",
    "        train_ += train\n",
    "        test_ += test\n",
    "    \n",
    "# data loader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn = CNN2(class_num)\n",
    "if use_cuda:\n",
    "    cnn = cnn.cuda()\n",
    "print(cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(cnn,train_loader, class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")                                                                                           \n",
    "print(\"DEVICE = {}\".format(DEVICE))                                                                                                                             \n",
    "criterion = nn.CrossEntropyLoss()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval()                                                                                                                                                      \n",
    "acc = 0.                                                                                                                                                        \n",
    "with torch.no_grad():                                                                                                                                           \n",
    "    for idx, (images, labels) in enumerate(test_loader):                                                                                                        \n",
    "        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )                                                                                     \n",
    "        y_hat = cnn(x) # (N, 10)                                                                                                                                \n",
    "        loss = criterion(y_hat, y)                                                                                                                              \n",
    "        _, indices = torch.max(y_hat, dim=-1)                                                                                                                   \n",
    "        acc += torch.sum(indices == y).item()                                                                                                                   \n",
    "print('*'*20, 'Test', '*'*20)                                                                                                                                   \n",
    "print('Loss: {}, Accuracy: {} %'.format(loss.item(), acc/(len(test_loader)*BATCH_SIZE)))                                                                          \n",
    "print('*'*46)   \n",
    "    #test(cnn)\n",
    "#loss 0.09 이하로 내려가는 방법 찾기\n",
    "'''\n",
    "torch.save({\n",
    "#'epoch': EPOCHS,                                                                                                                                                                                     \n",
    "'model_state_dict': cnn.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss\n",
    "    }, \"./model_save/model_HW_CNN2_.pth\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    acc = 0 \n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        #print(test_imgs.shape)\n",
    "        test_imgs, test_labels = test_imgs.to(DEVICE), test_labels.to(DEVICE)\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        #if use_cuda:\n",
    "        #    test_imgs, test_labels = test_imgs.cuda(), test_labels.cuda()\n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        acc += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}\".format( float(acc) / (len(test_loader)*BATCH_SIZE)))\n",
    "\n",
    "\n",
    "'''\n",
    "def test(model, test_loader):\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"DEVICE = {}\".format(DEVICE))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    #model = TheModelClass(*args, **kwargs)                                                                              \n",
    "    #optimizer = TheOptimizerClass(*args, **kwargs)                                                                      \n",
    "    checkpoint = torch.load(\"./model_save/model_HW_CNN2.pth\")\n",
    "    cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "    #optimizers.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    #num_epochs = checkpoint['epoch']                                                                                    \n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    cnn.eval()\n",
    "    acc = 0.\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels) in enumerate(test_loader):\n",
    "            x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
    "            y_hat = cnn(x) # (N, 10)\n",
    "            loss = criterion(y_hat, y)\n",
    "            _, indices = torch.max(y_hat, dim=-1)\n",
    "            acc += torch.sum(indices == y).item()\n",
    "    print('*'*20, 'Test', '*'*20)\n",
    "    print('Loss: {}, Accuracy: {} %'.format(loss.item(), acc/len(test_loader)*BATCH_SIZE))\n",
    "    print('*'*46)\n",
    "'''\n",
    "\n",
    "#test(cnn, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
